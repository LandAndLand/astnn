{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.6 64-bit ('normal')",
   "display_name": "Python 3.8.6 64-bit ('normal')",
   "metadata": {
    "interpreter": {
     "hash": "f00aa4d08b5dbe9a4f4240f8270de016ce9f4f5bdff9dc19e01b094329a335d5"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "HIDDEN_DIM = 100\n",
    "ENCODE_DIM = 128\n",
    "LABELS = 1\n",
    "EPOCHS = 1\n",
    "BATCH_SIZE = 3\n",
    "USE_GPU = False\n",
    "root = 'data/'\n",
    "language = 'c'\n",
    "EMBEDDING_DIM = 128\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_pickle(root+language+'/train/blocks.pkl').sample(frac=1)\n",
    "test_data = pd.read_pickle(root+language+'/test/blocks.pkl').sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.word2vec import Word2Vec\n",
    "\n",
    "word2vec = Word2Vec.load(root+language+\"/train/embedding_astnode_w2v_\"+str(EMBEDDING_DIM)).wv\n",
    "MAX_TOKENS = word2vec.syn0.shape[0]\n",
    "EMBEDDING_DIM = word2vec.syn0.shape[1]\n",
    "\n",
    "embeddings = np.zeros((MAX_TOKENS + 1, EMBEDDING_DIM), dtype=\"float32\")\n",
    "embeddings[:word2vec.syn0.shape[0]] = word2vec.syn0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import random\n",
    "\n",
    "\n",
    "class BatchTreeEncoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, encode_dim, batch_size, use_gpu, pretrained_weight=None):\n",
    "        super(BatchTreeEncoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.encode_dim = encode_dim\n",
    "        self.W_c = nn.Linear(embedding_dim, encode_dim)\n",
    "        self.activation = F.relu\n",
    "        self.stop = -1\n",
    "        self.batch_size = batch_size\n",
    "        self.use_gpu = use_gpu\n",
    "        self.node_list = []\n",
    "        self.th = torch.cuda if use_gpu else torch\n",
    "        self.batch_node = None\n",
    "        self.max_index = vocab_size\n",
    "        # pretrained  embedding\n",
    "        if pretrained_weight is not None:\n",
    "            self.embedding.weight.data.copy_(\n",
    "                torch.from_numpy(pretrained_weight))\n",
    "            # self.embedding.weight.requires_grad = False\n",
    "\n",
    "    def create_tensor(self, tensor):\n",
    "        if self.use_gpu:\n",
    "            return tensor.cuda()\n",
    "        return tensor\n",
    "\n",
    "    def traverse_mul(self, node, batch_index):\n",
    "        size = len(node)\n",
    "        if not size:\n",
    "            return None\n",
    "        batch_current = self.create_tensor(\n",
    "            Variable(torch.zeros(size, self.embedding_dim)))\n",
    "\n",
    "        index, children_index = [], []\n",
    "        current_node, children = [], []\n",
    "        for i in range(size):\n",
    "            # if node[i][0] is not -1:\n",
    "            index.append(i)\n",
    "            current_node.append(node[i][0])\n",
    "            temp = node[i][1:]\n",
    "            c_num = len(temp)\n",
    "            for j in range(c_num):\n",
    "                if temp[j][0] is not -1:\n",
    "                    if len(children_index) <= j:\n",
    "                        children_index.append([i])\n",
    "                        children.append([temp[j]])\n",
    "                    else:\n",
    "                        children_index[j].append(i)\n",
    "                        children[j].append(temp[j])\n",
    "            # else:\n",
    "            #     batch_index[i] = -1\n",
    "\n",
    "        batch_current = self.W_c(batch_current.index_copy(0, Variable(self.th.LongTensor(index)),\n",
    "                                                          self.embedding(Variable(self.th.LongTensor(current_node)))))\n",
    "\n",
    "        for c in range(len(children)):\n",
    "            zeros = self.create_tensor(\n",
    "                Variable(torch.zeros(size, self.encode_dim)))\n",
    "            batch_children_index = [batch_index[i] for i in children_index[c]]\n",
    "            tree = self.traverse_mul(children[c], batch_children_index)\n",
    "            if tree is not None:\n",
    "                batch_current += zeros.index_copy(0, Variable(\n",
    "                    self.th.LongTensor(children_index[c])), tree)\n",
    "        # batch_index = [i for i in batch_index if i is not -1]\n",
    "        b_in = Variable(self.th.LongTensor(batch_index))\n",
    "        self.node_list.append(\n",
    "            self.batch_node.index_copy(0, b_in, batch_current))\n",
    "        return batch_current\n",
    "\n",
    "    def forward(self, x, bs):\n",
    "        self.batch_size = bs\n",
    "        self.batch_node = self.create_tensor(\n",
    "            Variable(torch.zeros(self.batch_size, self.encode_dim)))\n",
    "        self.node_list = []\n",
    "        self.traverse_mul(x, list(range(self.batch_size)))\n",
    "        self.node_list = torch.stack(self.node_list)\n",
    "        return torch.max(self.node_list, 0)[0]\n",
    "\n",
    "\n",
    "class BatchProgramCC(nn.Module):\n",
    "    def __init__(self, embedding_dim, hidden_dim, vocab_size, encode_dim, label_size, batch_size, use_gpu=True, pretrained_weight=None):\n",
    "        super(BatchProgramCC, self).__init__()\n",
    "        self.stop = [vocab_size-1]\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = 1\n",
    "        self.gpu = use_gpu\n",
    "        self.batch_size = batch_size\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.encode_dim = encode_dim\n",
    "        self.label_size = label_size\n",
    "        self.encoder = BatchTreeEncoder(self.vocab_size, self.embedding_dim, self.encode_dim,\n",
    "                                        self.batch_size, self.gpu, pretrained_weight)\n",
    "        self.root2label = nn.Linear(self.encode_dim, self.label_size)\n",
    "        # gru\n",
    "        self.bigru = nn.GRU(self.encode_dim, self.hidden_dim, num_layers=self.num_layers, bidirectional=True,\n",
    "                            batch_first=True)\n",
    "        # linear\n",
    "        self.hidden2label = nn.Linear(\n",
    "            self.hidden_dim * 2 * 30, self.label_size)\n",
    "        # hidden\n",
    "        self.hidden = self.init_hidden()\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "\n",
    "        # 关于attention的\n",
    "        self.W_s1 = nn.Linear(2 * self.hidden_dim, 350)\n",
    "        self.W_s2 = nn.Linear(350, 30)\n",
    "        # self.fc_layer = nn.Linear(30*2*hidden_size, 2000)\n",
    "\n",
    "    def init_hidden(self):\n",
    "        if self.gpu is True:\n",
    "            if isinstance(self.bigru, nn.LSTM):\n",
    "                h0 = Variable(torch.zeros(self.num_layers * 2,\n",
    "                                          self.batch_size, self.hidden_dim).cuda())\n",
    "                c0 = Variable(torch.zeros(self.num_layers * 2,\n",
    "                                          self.batch_size, self.hidden_dim).cuda())\n",
    "                return h0, c0\n",
    "            return Variable(torch.zeros(self.num_layers * 2, self.batch_size, self.hidden_dim)).cuda()\n",
    "        else:\n",
    "            return Variable(torch.zeros(self.num_layers * 2, self.batch_size, self.hidden_dim))\n",
    "\n",
    "    def get_zeros(self, num):\n",
    "        zeros = Variable(torch.zeros(num, self.encode_dim))\n",
    "        if self.gpu:\n",
    "            return zeros.cuda()\n",
    "        return zeros\n",
    "\n",
    "    def attention_net(self, bigru_out):\n",
    "        \"\"\"\n",
    "        Now we will use self attention mechanism to produce a matrix embedding of the input sentence in which every row represents an\n",
    "                encoding of the input sentence but giving an attention to a specific part of the sentence. \n",
    "\n",
    "        We will use 30 such embedding of the input sentence and then finally we will concatenate all the 30 sentence embedding vectors and connect it to a fully \n",
    "                connected layer of size 2000 which will be connected to the output layer of size 2 returning logits for our two classes i.e., \n",
    "                pos & neg.\n",
    "\n",
    "                Arguments\n",
    "                ---------\n",
    "                lstm_output = A tensor containing hidden states corresponding to each time step of the LSTM network.\n",
    "                ---------\n",
    "                Returns : Final Attention weight matrix for all the 30 different sentence embedding in which each of 30 embeddings give\n",
    "                                  attention to different parts of the input sentence.\n",
    "                Tensor size : lstm_output.size() = (batch_size, Fnum_seq, 2*hidden_size)\n",
    "                                          attn_weight_matrix.size() = (batch_size, 30, num_seq)\n",
    "                \"\"\"\n",
    "\n",
    "        attn_weight_matrix = self.W_s2(F.tanh(self.W_s1(bigru_out)))\n",
    "        attn_weight_matrix = attn_weight_matrix.permute(0, 2, 1)\n",
    "        attn_weight_matrix = F.softmax(attn_weight_matrix, dim=2)\n",
    "\n",
    "        return attn_weight_matrix\n",
    "\n",
    "    def encode(self, x):\n",
    "        # 取一个batch中的所有ast的 最大语句树个数\n",
    "        lens = [len(item) for item in x]\n",
    "        max_len = max(lens)\n",
    "\n",
    "        encodes = []\n",
    "        # 对每一个样本i\n",
    "        for i in range(self.batch_size):\n",
    "            # 取样本i的每一个语句树j\n",
    "            for j in range(lens[i]):\n",
    "                encodes.append(x[i][j])\n",
    "\n",
    "        encodes = self.encoder(encodes, sum(lens))\n",
    "        seq, start, end = [], 0, 0\n",
    "        for i in range(self.batch_size):\n",
    "            end += lens[i]\n",
    "            if max_len-lens[i]:\n",
    "                seq.append(self.get_zeros(max_len-lens[i]))\n",
    "            seq.append(encodes[start:end])\n",
    "            start = end\n",
    "        encodes = torch.cat(seq)\n",
    "        encodes = encodes.view(self.batch_size, max_len, -1)\n",
    "        # return encodes\n",
    "        gru_out, hidden = self.bigru(encodes, self.hidden)\n",
    "        # print(gru_out.size())\n",
    "        # (batch_size, num_seq, 2*encode_dim) 是输入到attention的表示\n",
    "        # print(hidden.size())\n",
    "        # (2, batch_size, encode_dim)\n",
    "\n",
    "        # pooling\n",
    "        #gru_out = F.max_pool1d(gru_out, gru_out.size(2)).squeeze(2)\n",
    "        # gru_out = gru_out[:,-1]\n",
    "        # gru_out.size() [atch_szie, 2* embedding_dim]\n",
    "\n",
    "        # attention\n",
    "        attn_weight_matrix = self.attention_net(gru_out)\n",
    "        hidden_matrix = torch.bmm(attn_weight_matrix, gru_out)\n",
    "        # hidden_matrix.size():[batch_size, 30, 2*embedding_dim]\n",
    "\n",
    "        # fully connected\n",
    "        gru_with_attn_out = hidden_matrix.view(\n",
    "            -1, hidden_matrix.size()[1]*hidden_matrix.size()[2])\n",
    "        # hidden_matrix.size(): [batch_size, 30*2*embedding_dim]\n",
    "\n",
    "        return gru_with_attn_out\n",
    "\n",
    "    # x1和x2都是输入的一个batch，每个batch包含：32个样本，每个样本是由ast拆分得到的所有语句树序列组成的\n",
    "    # 即：每个样本是一个完整的ast树拆分得到的语句树组成，这些语句树的每个结点都被word2vec嵌入表示\n",
    "    # ast的某个语句树的表示形式: [1, [21, [34, [50]], [138]]]\n",
    "    # 同一个list中的结点是兄弟结点, 临近的在不同list的结点是父母-孩子结点关系, 如21是1的孩子结点, 34是21的孩子结点\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        lvec, rvec = self.encode(x1), self.encode(x2)\n",
    "        # print(lvec.size(), rvec.size())\n",
    "        # (batch_size,3*2*embedding_dim)\n",
    "        # 一维范数计算两个编码的距离\n",
    "        abs_dist = torch.abs(torch.add(lvec, -rvec))\n",
    "        # print(abs_dist.size())\n",
    "        # (batch_size,3*2*embedding_dim)\n",
    "        y = torch.sigmoid(self.hidden2label(abs_dist))\n",
    "        return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from model import BatchProgramCC\n",
    "\n",
    "model = BatchProgramCC(EMBEDDING_DIM,\n",
    "                        HIDDEN_DIM,\n",
    "                        MAX_TOKENS+1,\n",
    "                        ENCODE_DIM,\n",
    "                        LABELS,\n",
    "                        BATCH_SIZE,\n",
    "                        USE_GPU, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "parameters = model.parameters()\n",
    "optimizer = torch.optim.Adamax(parameters)\n",
    "loss_function = torch.nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(dataset, idx, bs):\n",
    "    tmp = dataset.iloc[idx: idx+bs]\n",
    "    x1, x2, labels = [], [], []\n",
    "    for _, item in tmp.iterrows():\n",
    "        x1.append(item['code_x'])\n",
    "        x2.append(item['code_y'])\n",
    "        labels.append([item['label']])\n",
    "    return x1, x2, torch.FloatTensor(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([3, 6000]) torch.Size([3, 6000])\ntorch.Size([3, 6000])\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "#from sklearn.metrics import precision_recall_fscore_support\n",
    "#from torch.utils.data import TensorDataset\n",
    "\n",
    "train_data_t, test_data_t = train_data.iloc[:3], test_data.iloc[:3]\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    start_time = time.time()\n",
    "    # training epoch\n",
    "    total_acc = 0.0\n",
    "    total_loss = 0.0\n",
    "    total = 0.0\n",
    "    i = 0\n",
    "    while i < len(train_data_t):\n",
    "        batch = get_batch(train_data_t, i, BATCH_SIZE)\n",
    "        i += BATCH_SIZE\n",
    "        train1_inputs, train2_inputs, train_labels = batch\n",
    "        if USE_GPU:\n",
    "            train1_inputs, train2_inputs, train_labels = train1_inputs, train2_inputs, train_labels.cuda()\n",
    "\n",
    "        #model.zero_grad()\n",
    "        optimizer.zero_grad()\n",
    "        model.batch_size = len(train_labels)\n",
    "        model.hidden = model.init_hidden()\n",
    "        output = model(train1_inputs, train2_inputs)\n",
    "\n",
    "        loss = loss_function(output, Variable(train_labels))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "#print(\"Testing-%d...\"%t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "data had benn preprocessed, please run file train.py \n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "if Path(root+'/'+language+'/'+'train/'+'blocks.pkl').exists():\n",
    "            print('data had benn preprocessed, please run file train.py ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}