{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.6 64-bit ('normal')",
   "display_name": "Python 3.8.6 64-bit ('normal')",
   "metadata": {
    "interpreter": {
     "hash": "f00aa4d08b5dbe9a4f4240f8270de016ce9f4f5bdff9dc19e01b094329a335d5"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycparser import c_parser\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "parser = c_parser.CParser()\n",
    "\n",
    "root = 'data/'\n",
    "language = 'c/'\n",
    "source = pd.read_pickle(root+language+'programs.pkl')\n",
    "#print(source)\n",
    "# label是指该段源代码来自于哪个类别吗？\n",
    "source.columns = ['id', 'code', 'label']\n",
    "print('parse starting')\n",
    "source['code'] = source['code'].apply(parser.parse)\n",
    "source.to_pickle(root+'c/ast.pkl')\n",
    "print('parse ending')\n",
    "#source_code = source['code'].iloc[0]\n",
    "#print(type(source_code))\n",
    "#ast= parser.parse(source_code)\n",
    "#ast.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import javalang\n",
    "def parse_program(func):\n",
    "    tokens = javalang.tokenizer.tokenize(func)\n",
    "    #print(f'tokens化得到的序列:{tokens}')\n",
    "    parser = javalang.parser.Parser(tokens)\n",
    "    tree = parser.parse_member_declaration()\n",
    "    return tree\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" func = '''public static int[] bubbleSort(int... a) {\n",
    "        boolean swapped;\n",
    "        do {\n",
    "            swapped = false;\n",
    "            for (int i = 0; i < a.length - 1; i++) {\n",
    "                if (a[i] > a[i + 1]) {\n",
    "                    int tmp = a[i];\n",
    "                    a[i] = a[i + 1];\n",
    "                    a[i + 1] = tmp;\n",
    "                    swapped = true;\n",
    "                }\n",
    "            }\n",
    "        } while (swapped);\n",
    "        return a;\n",
    "    }\n",
    "\n",
    "'''\n",
    "ast = parse_program(func) \"\"\"\n",
    "# for path, node in ast:\n",
    "#   print(path, node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "parse starting\n",
      "parse ending\n"
     ]
    }
   ],
   "source": [
    "from pycparser import c_parser\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "root = 'data/'\n",
    "language = 'java/'\n",
    "source_java = pd.read_csv(root+language+'bcb_funcs_all.tsv',\n",
    "                            sep='\\t', \n",
    "                            header=None, \n",
    "                            encoding='utf-8')\n",
    "source_java.columns = ['id', 'code']\n",
    "print('parse starting')\n",
    "source_java['code'] = source_java['code'].apply(parse_program)\n",
    "source_java.to_pickle('data/java/ast.pkl')\n",
    "print('parse ending')\n",
    "#java = source_java['code'].iloc[2]\n",
    "#print(java)\n",
    "#source['code'] = source['code'].apply(parse_program)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 分割pairs 胃训练集、验证集、测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "def split_data(root = 'data/', ratio = '3:1:1', language = 'c'):\n",
    "  if language is 'c':\n",
    "    filename = 'oj_clone_ids.pkl'\n",
    "  else:\n",
    "    filename = 'bcb_pair_ids.pkl'\n",
    "  path = root + language + '/' + filename\n",
    "  data = pd.read_pickle(path)\n",
    "  data_num = len(data)\n",
    "  ratios = [int(r) for r in ratio.split(':')]\n",
    "  train_split = int(ratios[0]/sum(ratios)*data_num)\n",
    "  val_split = train_split + int(ratios[1]/sum(ratios)*data_num)\n",
    "  \n",
    "  #对要分割的数据进行随机打散\n",
    "  print('starting split')\n",
    "  data = data.sample(frac=1, random_state=666)\n",
    "\n",
    "  train = data.iloc[:train_split]\n",
    "  dev = data.iloc[train_split:val_split]\n",
    "  test = data.iloc[val_split:]\n",
    "\n",
    "  def check_or_create(path):\n",
    "    if not os.path.exists(path):\n",
    "      os.mkdir(path) \n",
    "  train_path = root+language+'/train/'\n",
    "  check_or_create(train_path)\n",
    "  assert Path(train_path).is_dir()\n",
    "  train_file_path = train_path + 'train.pkl'\n",
    "  train.to_pickle(train_file_path)\n",
    "\n",
    "  dev_path = root+language+'/dev/'\n",
    "  check_or_create(dev_path)\n",
    "  dev_file_path = dev_path + 'dev.pkl'\n",
    "  train.to_pickle(dev_file_path)\n",
    "\n",
    "  test_path = root+language+'/test/'\n",
    "  check_or_create(test_path)\n",
    "  test_file_path = test_path + 'test.pkl'\n",
    "  test.to_pickle(test_file_path)\n",
    "  print('end split')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "starting split\n",
      "end split\n",
      "starting split\n",
      "end split\n"
     ]
    }
   ],
   "source": [
    "split_data(language='c')\n",
    "split_data(language = 'java')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "language = 'c'\n",
    "train_file_path = 'clone/data/'+language+'/train/train.pkl'\n",
    "dev_file_path = 'clone/data/'+language+'/dev/train.pkl'\n",
    "test_file_path = 'clone/data/'+language+'/test/train.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def read_ast(language):\n",
    "  root = 'data/'\n",
    "  source = pd.read_pickle(root+language+'/ast.pkl')\n",
    "  print(len(source['code']))\n",
    "  return source\n",
    "  # ast = source['code'].iloc[1]\n",
    "  # ast.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#source = read_ast('c')\n",
    "source_c_ast_DF = read_ast('c')\n",
    "#source_java_ast_DF = read_ast('java')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = 'data/'\n",
    "language = 'c'\n",
    "train_file_path = root + language + '/train/train.pkl'\n",
    "pairs = pd.read_pickle(train_file_path)\n",
    "# 找到训练集所包含的所有的source code id\n",
    "train_ids = pairs['id1'].append(pairs['id2']).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([9566, 8200, 3897, ..., 9254, 3971, 39727], dtype=object)"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "train_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# func函数每次处理ast的当前遍历到的结点。即剩余子树的根节点\n",
    "def func(root,sequence):\n",
    "  #print(f'c: partial ast root: {root.__class__.__name__}')\n",
    "  current = SingleNode(root)\n",
    "  sequence.append(current.get_token())\n",
    "  #print(f'sequence: {sequence}')\n",
    "  for _, child in root.children():\n",
    "      func(child, sequence)\n",
    "  if current.get_token().lower() == 'compound':\n",
    "      sequence.append('End')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trans_to_sequences(ast):\n",
    "    sequence = []\n",
    "    func(ast, sequence)\n",
    "    return sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "id\n9566     [FileAST, Decl, ArrayDecl, a, int, 200, Decl, ...\n8200     [FileAST, FuncDef, Decl, FuncDecl, main, int, ...\n3897     [FileAST, FuncDef, Decl, FuncDecl, main, int, ...\n12786    [FileAST, FuncDef, Decl, FuncDecl, main, int, ...\n34502    [FileAST, Decl, ArrayDecl, ArrayDecl, map, int...\n                               ...                        \n29794    [FileAST, Decl, a, int, 0, Decl, i, int, 0, De...\n49967    [FileAST, FuncDef, Decl, FuncDecl, main, int, ...\n9254     [FileAST, FuncDef, Decl, FuncDecl, main, int, ...\n3971     [FileAST, FuncDef, Decl, FuncDecl, main, int, ...\n39727    [FileAST, FuncDef, Decl, FuncDecl, main, int, ...\nName: code, Length: 7498, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# 设置ast_DFs的索引为id\n",
    "ast_DFs = source_c_ast_DF.set_index('id',drop=False).loc[train_ids]\n",
    "#print(ast_DFs)\n",
    "\n",
    "asts = ast_DFs['code']\n",
    "sequence = []\n",
    "corpus = asts.apply(trans_to_sequences)\n",
    "print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(type(corpus)) # Series\n",
    "str_corpus = [' '.join(c) for c in corpus]\n",
    "ast_seq = source_c_ast_DF.copy(False)\n",
    "ast_seq['code'] = pd.Series(str_corpus)\n",
    "ast_seq.to_pickle(root+language+'/train/ast_seq.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'corpus' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-f284720b987e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword2vec\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mWord2Vec\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0membedding_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m128\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mw2v\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mWord2Vec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0membedding_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_final_vocab\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mw2v\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'/train/embedding_astnode_w2v_'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0membedding_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'corpus' is not defined"
     ]
    }
   ],
   "source": [
    "# 使用word2vec从训练集中训练一个词典\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "embedding_size = 128\n",
    "w2v = Word2Vec(corpus, size=embedding_size, workers=16, sg=1, max_final_vocab=3000)\n",
    "w2v.save(root+language+'/train/embedding_astnode_w2v_' + str(embedding_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from tree import ASTNode, SingleNode \n",
    "from prepare_data import get_blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate block sequences with index representations\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "embedding_size = 128\n",
    "def generate_block_seqs():\n",
    "    word2vec = Word2Vec.load(root+language+'/train/embedding_astnode_w2v_' + str(embedding_size)).wv\n",
    "    vocab = word2vec.vocab\n",
    "    max_token = word2vec.syn0.shape[0]\n",
    "    \n",
    "    # 这个递归函数用来干什么？\n",
    "    def tree_to_index(node):\n",
    "        token = node.token\n",
    "        result = [vocab[token].index if token in vocab else max_token]\n",
    "        children = node.children\n",
    "        for child in children:\n",
    "            #print(f'tree_to_index: a node''s child: {child.token}')\n",
    "            result.append(tree_to_index(child))\n",
    "        return result\n",
    "\n",
    "    def trans2seq(ast):\n",
    "        blocks = []\n",
    "        get_blocks(ast, blocks)\n",
    "        tree = []\n",
    "        for b in blocks:\n",
    "            btree = tree_to_index(b)\n",
    "            tree.append(btree)\n",
    "        return tree\n",
    "    # source_c_ast_DF就是id code(ast形式) label \n",
    "    source_2_seq_DF =  source_c_ast_DF.copy(False)\n",
    "    trees = source_2_seq_DF['code']\n",
    "    # 确认trees copy成功\n",
    "    #print(trees)\n",
    "    # trans2seq操作是在ast上进行的\n",
    "    # 把每一个ast转换成seq blocks\n",
    "    # print(trees['code'].iloc[1])\n",
    "    source_2_seq_DF['code'] = trees.apply(trans2seq)\n",
    "    if 'label' in source_2_seq_DF.columns:\n",
    "        source_2_seq_DF.drop('label', axis=1, inplace=True)\n",
    "    blocks = source_2_seq_DF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_block_seqs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'get_blocks' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-a1294bc322ac>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#generate_block_seqs()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mblocks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mget_blocks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mast_for_block\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mblocks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;31m#print(blocks)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'get_blocks' is not defined"
     ]
    }
   ],
   "source": [
    "#generate_block_seqs()\n",
    "blocks = []\n",
    "get_blocks(ast_for_block,blocks)\n",
    "#print(blocks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "FuncDef\ntree_to_index: a node  child: Decl\ntree_to_index: a node  child: FuncDecl\ntree_to_index: a node  child: main\ntree_to_index: a node  child: int\n[30, [1, [29, [40, [2]]]]]\nCompound\n[6]\nDecl\ntree_to_index: a node  child: ArrayDecl\ntree_to_index: a node  child: s\ntree_to_index: a node  child: char\ntree_to_index: a node  child: 256\n[1, [21, [34, [50]], [138]]]\nDecl\ntree_to_index: a node  child: ArrayDecl\ntree_to_index: a node  child: a\ntree_to_index: a node  child: char\ntree_to_index: a node  child: 256\n[1, [21, [12, [50]], [138]]]\nDecl\ntree_to_index: a node  child: ArrayDecl\ntree_to_index: a node  child: b\ntree_to_index: a node  child: char\ntree_to_index: a node  child: 256\n[1, [21, [24, [50]], [138]]]\nDecl\ntree_to_index: a node  child: l1\ntree_to_index: a node  child: int\n[1, [163, [2]]]\nDecl\ntree_to_index: a node  child: i\ntree_to_index: a node  child: int\n[1, [0, [2]]]\nDecl\ntree_to_index: a node  child: j\ntree_to_index: a node  child: int\n[1, [8, [2]]]\nDecl\ntree_to_index: a node  child: n\ntree_to_index: a node  child: int\n[1, [13, [2]]]\nDecl\ntree_to_index: a node  child: flag\ntree_to_index: a node  child: int\n[1, [118, [2]]]\nFuncCall\ntree_to_index: a node  child: scanf\ntree_to_index: a node  child: ExprList\ntree_to_index: a node  child: \"%s\"\ntree_to_index: a node  child: s\n[9, [28], [10, [105], [34]]]\nFuncCall\ntree_to_index: a node  child: scanf\ntree_to_index: a node  child: ExprList\ntree_to_index: a node  child: \"%s\"\ntree_to_index: a node  child: a\n[9, [28], [10, [105], [12]]]\nFuncCall\ntree_to_index: a node  child: scanf\ntree_to_index: a node  child: ExprList\ntree_to_index: a node  child: \"%s\"\ntree_to_index: a node  child: b\n[9, [28], [10, [105], [24]]]\n=\ntree_to_index: a node  child: l1\ntree_to_index: a node  child: FuncCall\ntree_to_index: a node  child: strlen\ntree_to_index: a node  child: ExprList\ntree_to_index: a node  child: a\n[4, [163], [9, [72], [10, [12]]]]\nFor\ntree_to_index: a node  child: =\ntree_to_index: a node  child: i\ntree_to_index: a node  child: 0\ntree_to_index: a node  child: !=\ntree_to_index: a node  child: ArrayRef\ntree_to_index: a node  child: s\ntree_to_index: a node  child: i\ntree_to_index: a node  child: '\u0000'\ntree_to_index: a node  child: ++\ntree_to_index: a node  child: i\n[15, [4, [0], [5]], [36, [3, [34], [0]], [2015]], [11, [0]]]\nCompound\n[6]\nIf\ntree_to_index: a node  child: ==\ntree_to_index: a node  child: ArrayRef\ntree_to_index: a node  child: s\ntree_to_index: a node  child: i\ntree_to_index: a node  child: ArrayRef\ntree_to_index: a node  child: a\ntree_to_index: a node  child: 0\n[18, [22, [3, [34], [0]], [3, [12], [5]]]]\nCompound\n[6]\n=\ntree_to_index: a node  child: flag\ntree_to_index: a node  child: 1\n[4, [118], [14]]\nFor\ntree_to_index: a node  child: =\ntree_to_index: a node  child: j\ntree_to_index: a node  child: +\ntree_to_index: a node  child: i\ntree_to_index: a node  child: 1\ntree_to_index: a node  child: <\ntree_to_index: a node  child: j\ntree_to_index: a node  child: +\ntree_to_index: a node  child: i\ntree_to_index: a node  child: l1\ntree_to_index: a node  child: ++\ntree_to_index: a node  child: j\n[15, [4, [8], [16, [0], [14]]], [17, [8], [16, [0], [163]]], [11, [8]]]\nCompound\n[6]\nIf\ntree_to_index: a node  child: !=\ntree_to_index: a node  child: ArrayRef\ntree_to_index: a node  child: s\ntree_to_index: a node  child: j\ntree_to_index: a node  child: ArrayRef\ntree_to_index: a node  child: a\ntree_to_index: a node  child: -\ntree_to_index: a node  child: j\ntree_to_index: a node  child: i\n[18, [36, [3, [34], [8]], [3, [12], [23, [8], [0]]]]]\n=\ntree_to_index: a node  child: flag\ntree_to_index: a node  child: 0\n[4, [118], [5]]\n=\ntree_to_index: a node  child: flag\ntree_to_index: a node  child: 1\n[4, [118], [14]]\nEnd\n[7]\nIf\ntree_to_index: a node  child: ==\ntree_to_index: a node  child: flag\ntree_to_index: a node  child: 1\n[18, [22, [118], [14]]]\nCompound\n[6]\nFor\ntree_to_index: a node  child: =\ntree_to_index: a node  child: n\ntree_to_index: a node  child: 0\ntree_to_index: a node  child: <\ntree_to_index: a node  child: n\ntree_to_index: a node  child: i\ntree_to_index: a node  child: ++\ntree_to_index: a node  child: n\n[15, [4, [13], [5]], [17, [13], [0]], [11, [13]]]\nFuncCall\ntree_to_index: a node  child: printf\ntree_to_index: a node  child: ExprList\ntree_to_index: a node  child: \"%c\"\ntree_to_index: a node  child: ArrayRef\ntree_to_index: a node  child: s\ntree_to_index: a node  child: n\n[9, [27], [10, [160], [3, [34], [13]]]]\nFuncCall\ntree_to_index: a node  child: printf\ntree_to_index: a node  child: ExprList\ntree_to_index: a node  child: \"%s\"\ntree_to_index: a node  child: b\n[9, [27], [10, [105], [24]]]\nFor\ntree_to_index: a node  child: =\ntree_to_index: a node  child: n\ntree_to_index: a node  child: +\ntree_to_index: a node  child: i\ntree_to_index: a node  child: l1\ntree_to_index: a node  child: !=\ntree_to_index: a node  child: ArrayRef\ntree_to_index: a node  child: s\ntree_to_index: a node  child: n\ntree_to_index: a node  child: '\u0000'\ntree_to_index: a node  child: ++\ntree_to_index: a node  child: n\n[15, [4, [13], [16, [0], [163]]], [36, [3, [34], [13]], [2015]], [11, [13]]]\nFuncCall\ntree_to_index: a node  child: printf\ntree_to_index: a node  child: ExprList\ntree_to_index: a node  child: \"%c\"\ntree_to_index: a node  child: ArrayRef\ntree_to_index: a node  child: s\ntree_to_index: a node  child: n\n[9, [27], [10, [160], [3, [34], [13]]]]\nReturn\ntree_to_index: a node  child: 0\n[35, [5]]\nEnd\n[7]\nEnd\n[7]\nEnd\n[7]\nFuncCall\ntree_to_index: a node  child: printf\ntree_to_index: a node  child: ExprList\ntree_to_index: a node  child: \"%s\"\ntree_to_index: a node  child: s\n[9, [27], [10, [105], [34]]]\nReturn\ntree_to_index: a node  child: 0\n[35, [5]]\nEnd\n[7]\n[[30, [1, [29, [40, [2]]]]], [6], [1, [21, [34, [50]], [138]]], [1, [21, [12, [50]], [138]]], [1, [21, [24, [50]], [138]]], [1, [163, [2]]], [1, [0, [2]]], [1, [8, [2]]], [1, [13, [2]]], [1, [118, [2]]], [9, [28], [10, [105], [34]]], [9, [28], [10, [105], [12]]], [9, [28], [10, [105], [24]]], [4, [163], [9, [72], [10, [12]]]], [15, [4, [0], [5]], [36, [3, [34], [0]], [2015]], [11, [0]]], [6], [18, [22, [3, [34], [0]], [3, [12], [5]]]], [6], [4, [118], [14]], [15, [4, [8], [16, [0], [14]]], [17, [8], [16, [0], [163]]], [11, [8]]], [6], [18, [36, [3, [34], [8]], [3, [12], [23, [8], [0]]]]], [4, [118], [5]], [4, [118], [14]], [7], [18, [22, [118], [14]]], [6], [15, [4, [13], [5]], [17, [13], [0]], [11, [13]]], [9, [27], [10, [160], [3, [34], [13]]]], [9, [27], [10, [105], [24]]], [15, [4, [13], [16, [0], [163]]], [36, [3, [34], [13]], [2015]], [11, [13]]], [9, [27], [10, [160], [3, [34], [13]]]], [35, [5]], [7], [7], [7], [9, [27], [10, [105], [34]]], [35, [5]], [7]]\n"
     ]
    }
   ],
   "source": [
    "from gensim.models.word2vec import Word2Vec\n",
    "embedding_size = 128\n",
    "root='data/'\n",
    "language = 'c'\n",
    "word2vec = Word2Vec.load(root+language+'/train/embedding_astnode_w2v_' + str(embedding_size)).wv\n",
    "vocab = word2vec.vocab\n",
    "max_token = word2vec.syn0.shape[0]\n",
    "\n",
    "def tree_to_index(node):\n",
    "    token = node.token\n",
    "    result = [vocab[token].index if token in vocab else max_token]\n",
    "    children = node.children\n",
    "    for child in children:\n",
    "        print(f'tree_to_index: a node  child: {child.token}')\n",
    "        result.append(tree_to_index(child))\n",
    "    return result\n",
    "tree = []\n",
    "for b in blocks:\n",
    "    print(b.token)\n",
    "    btree = tree_to_index(b)\n",
    "    print(btree)\n",
    "    tree.append(btree)\n",
    "print(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-3-d6d65541cb23>, line 2)",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-3-d6d65541cb23>\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    max_len = max(lens)\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "lens = [len(item) for item in tree]\n",
    "        max_len = max(lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "FuncDef\n['Decl']\nCompound\n[]\nDecl\n['ArrayDecl']\nDecl\n['ArrayDecl']\nDecl\n['ArrayDecl']\nDecl\n['l1']\nDecl\n['i']\nDecl\n['j']\nDecl\n['n']\nDecl\n['flag']\nFuncCall\n['scanf', 'ExprList']\nFuncCall\n['scanf', 'ExprList']\nFuncCall\n['scanf', 'ExprList']\n=\n['l1', 'FuncCall']\nFor\n['=', '!=', '++']\nCompound\n[]\nIf\n['==']\nCompound\n[]\n=\n['flag', '1']\nFor\n['=', '<', '++']\nCompound\n[]\nIf\n['!=']\n=\n['flag', '0']\n=\n['flag', '1']\nEnd\n[]\nIf\n['==']\nCompound\n[]\nFor\n['=', '<', '++']\nFuncCall\n['printf', 'ExprList']\nFuncCall\n['printf', 'ExprList']\nFor\n['=', '!=', '++']\nFuncCall\n['printf', 'ExprList']\nReturn\n['0']\nEnd\n[]\nEnd\n[]\nEnd\n[]\nFuncCall\n['printf', 'ExprList']\nReturn\n['0']\nEnd\n[]\n"
     ]
    }
   ],
   "source": [
    "for b in blocks:\n",
    "    print(b.token)\n",
    "    children = b.children\n",
    "    child_list = [c.token for c in children]\n",
    "    print(child_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "code = '''int main()\n",
    "{\n",
    "\tchar s[256],a[256],b[256];\n",
    "\tint l1,i,j,n;\n",
    "\tint flag;\n",
    "\tscanf(\"%s\",s);\n",
    "\tscanf(\"%s\",a);\n",
    "\tscanf(\"%s\",b);\n",
    "\tl1=strlen(a);\n",
    "\tfor(i=0;s[i]!='\\0';i++)\n",
    "\t{\n",
    "\t\tif(s[i]==a[0])\n",
    "\t\t{\n",
    "\t\t\tflag=1;\n",
    "\t\t\tfor(j=i+1;j<(i+l1);j++)\n",
    "\t\t\t{\n",
    "\t\t\t\tif (s[j]!=a[j-i])\n",
    "\t\t\t\t\tflag=0;\n",
    "\t\t\t\telse \n",
    "\t\t\t\t    flag=1;\n",
    "\t\t\t}\n",
    "\t\t\tif(flag==1)\n",
    "\t\t\t{\n",
    "\t\t\t\tfor(n=0;n<i;n++)\n",
    "\t\t\t\t\tprintf(\"%c\",s[n]);\n",
    "\t\t\t\tprintf(\"%s\",b);\n",
    "\t\t\t\tfor(n=i+l1;s[n]!='\\0';n++)\n",
    "\t\t\t\t\tprintf(\"%c\",s[n]);\n",
    "\t\t\t\treturn 0;\n",
    "\t\t\t}\n",
    "\t\t}\n",
    "\t}\n",
    "\tprintf(\"%s\",s);\n",
    "\treturn 0;\n",
    "}\n",
    "'''\n",
    "#print(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<pycparser.c_ast.FileAST object at 0x0000017185DB9140>\n"
     ]
    }
   ],
   "source": [
    "from pycparser import c_parser\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "parser = c_parser.CParser()\n",
    "\n",
    "ast_for_block = parser.parse(code)\n",
    "print(ast_for_block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "          id                                               code  label\n",
       "0          0  <pycparser.c_ast.FileAST object at 0x000001AAA...     97\n",
       "1          1  <pycparser.c_ast.FileAST object at 0x000001AAA...     97\n",
       "2          2  <pycparser.c_ast.FileAST object at 0x000001AAA...     97\n",
       "3          3  <pycparser.c_ast.FileAST object at 0x000001AAA...     97\n",
       "4          4  <pycparser.c_ast.FileAST object at 0x000001AAA...     97\n",
       "...      ...                                                ...    ...\n",
       "51996  51996  <pycparser.c_ast.FileAST object at 0x000001AC2...     72\n",
       "51997  51997  <pycparser.c_ast.FileAST object at 0x000001AC2...     72\n",
       "51998  51998  <pycparser.c_ast.FileAST object at 0x000001AC2...     72\n",
       "51999  51999  <pycparser.c_ast.FileAST object at 0x000001AC2...     72\n",
       "52000  52000  <pycparser.c_ast.FileAST object at 0x000001AC2...     72\n",
       "\n",
       "[52001 rows x 3 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>code</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>&lt;pycparser.c_ast.FileAST object at 0x000001AAA...</td>\n      <td>97</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>&lt;pycparser.c_ast.FileAST object at 0x000001AAA...</td>\n      <td>97</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>&lt;pycparser.c_ast.FileAST object at 0x000001AAA...</td>\n      <td>97</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>&lt;pycparser.c_ast.FileAST object at 0x000001AAA...</td>\n      <td>97</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>&lt;pycparser.c_ast.FileAST object at 0x000001AAA...</td>\n      <td>97</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>51996</th>\n      <td>51996</td>\n      <td>&lt;pycparser.c_ast.FileAST object at 0x000001AC2...</td>\n      <td>72</td>\n    </tr>\n    <tr>\n      <th>51997</th>\n      <td>51997</td>\n      <td>&lt;pycparser.c_ast.FileAST object at 0x000001AC2...</td>\n      <td>72</td>\n    </tr>\n    <tr>\n      <th>51998</th>\n      <td>51998</td>\n      <td>&lt;pycparser.c_ast.FileAST object at 0x000001AC2...</td>\n      <td>72</td>\n    </tr>\n    <tr>\n      <th>51999</th>\n      <td>51999</td>\n      <td>&lt;pycparser.c_ast.FileAST object at 0x000001AC2...</td>\n      <td>72</td>\n    </tr>\n    <tr>\n      <th>52000</th>\n      <td>52000</td>\n      <td>&lt;pycparser.c_ast.FileAST object at 0x000001AC2...</td>\n      <td>72</td>\n    </tr>\n  </tbody>\n</table>\n<p>52001 rows × 3 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "source_c_ast_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}